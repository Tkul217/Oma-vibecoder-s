#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π —Å –ø–æ–≤—ã—à–µ–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, models
from PIL import Image
import numpy as np
import random
import os
import cv2
from typing import Dict, List, Tuple, Optional
import torchvision.transforms.functional as TF
from torch.nn import MultiheadAttention

class SpatialAttention(nn.Module):
    """Spatial Attention –º–æ–¥—É–ª—å –¥–ª—è —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∏ –Ω–∞ –≤–∞–∂–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö"""
    def __init__(self, in_channels):
        super(SpatialAttention, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, 1, kernel_size=1)
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        attention = self.conv1(x)
        attention = self.sigmoid(attention)
        return x * attention

class ChannelAttention(nn.Module):
    """Channel Attention –º–æ–¥—É–ª—å"""
    def __init__(self, in_channels, reduction=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        self.fc = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),
            nn.ReLU(),
            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        attention = self.sigmoid(avg_out + max_out)
        return x * attention

class ImprovedCarConditionClassifier(nn.Module):
    def __init__(self, num_classes_clean=2, num_classes_damage=2, dropout_rate=0.3):
        super(ImprovedCarConditionClassifier, self).__init__()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º EfficientNet-B3 –∫–∞–∫ –±–æ–ª–µ–µ –º–æ—â–Ω—ã–π backbone
        try:
            from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights
            self.backbone = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)
            feature_dim = self.backbone.classifier[1].in_features
            self.backbone.classifier = nn.Identity()
            print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è EfficientNet-B3")
        except Exception as e:
            # Fallback –Ω–∞ ResNet50 –µ—Å–ª–∏ EfficientNet –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
            print(f"‚ö†Ô∏è EfficientNet –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({e}), –∏—Å–ø–æ–ª—å–∑—É–µ–º ResNet50")
            self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)
            feature_dim = self.backbone.fc.in_features
            self.backbone.fc = nn.Identity()
        
        # Attention –º–µ—Ö–∞–Ω–∏–∑–º—ã
        self.channel_attention = ChannelAttention(feature_dim)
        self.spatial_attention = SpatialAttention(feature_dim)
        
        # –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.global_max_pool = nn.AdaptiveMaxPool2d(1)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
        self.feature_dim = feature_dim
        self.is_efficientnet = True  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –≤ forward
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Å –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
        self.cleanliness_head = nn.Sequential(
            nn.Linear(feature_dim, 512),  # –î–ª—è EfficientNet –∏—Å–ø–æ–ª—å–∑—É–µ–º feature_dim –Ω–∞–ø—Ä—è–º—É—é
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5),
            nn.Linear(256, num_classes_clean)
        )
        
        self.damage_head = nn.Sequential(
            nn.Linear(feature_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5),
            nn.Linear(256, num_classes_damage)
        )
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏
        self.overall_head = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5),
            nn.Linear(256, 4)  # 4 –∫–ª–∞—Å—Å–∞: clean_intact, clean_damaged, dirty_intact, dirty_damaged
        )
        
    def forward(self, x):
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = self.backbone(x)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if len(features.shape) == 2:
            # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ —É–∂–µ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–µ (EfficientNet), –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
            global_features = features
        else:
            # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–µ (ResNet), –ø—Ä–∏–º–µ–Ω—è–µ–º attention
            features = self.channel_attention(features)
            features = self.spatial_attention(features)
            
            # –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            avg_pool = self.global_pool(features).view(features.size(0), -1)
            max_pool = self.global_max_pool(features).view(features.size(0), -1)
            global_features = torch.cat([avg_pool, max_pool], dim=1)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        cleanliness_logits = self.cleanliness_head(global_features)
        damage_logits = self.damage_head(global_features)
        overall_logits = self.overall_head(global_features)
        
        return cleanliness_logits, damage_logits, overall_logits

class AdvancedCarAnalyzer:
    def __init__(self, model_path=None, confidence_threshold=0.7):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.confidence_threshold = confidence_threshold
        self.model = ImprovedCarConditionClassifier()
        self.model.to(self.device)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—Å—Ç—å
        if model_path and os.path.exists(model_path):
            try:
                checkpoint = torch.load(model_path, map_location=self.device)
                if 'model_state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                else:
                    self.model.load_state_dict(checkpoint)
                self.model.eval()
                print(f"‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
                self.trained = True
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                print("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–µ–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (–¥–µ–º–æ —Ä–µ–∂–∏–º)")
                self.model.eval()
                self.trained = False
        else:
            print("üîÑ –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ–º–æ —Ä–µ–∂–∏–º")
            self.model.eval()
            self.trained = False
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.transform = transforms.Compose([
            transforms.Resize((300, 300)),  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
            transforms.CenterCrop(256),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        self.augment_transform = transforms.Compose([
            transforms.Resize((320, 320)),
            transforms.RandomCrop(256),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=10),
            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),
            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        self.class_names = {
            'cleanliness': ['–ß–∏—Å—Ç—ã–π', '–ì—Ä—è–∑–Ω—ã–π'],
            'damage': ['–¶–µ–ª—ã–π', '–ë–∏—Ç—ã–π'],
            'overall': ['–ß–∏—Å—Ç—ã–π —Ü–µ–ª—ã–π', '–ß–∏—Å—Ç—ã–π –±–∏—Ç—ã–π', '–ì—Ä—è–∑–Ω—ã–π —Ü–µ–ª—ã–π', '–ì—Ä—è–∑–Ω—ã–π –±–∏—Ç—ã–π']
        }
    
    def preprocess_image(self, image):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        elif isinstance(image, np.ndarray):
            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è (–ø—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è)
        image = self._crop_car_region(image)
        
        return image
    
    def _crop_car_region(self, image):
        """–ü–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–µ–∑–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ –æ–±–ª–∞—Å—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ OpenCV —Ñ–æ—Ä–º–∞—Ç
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # –ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –∫–æ–Ω—Ç—É—Ä–æ–≤
            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª—å—à–∏–π –∫–æ–Ω—Ç—É—Ä
                largest_contour = max(contours, key=cv2.contourArea)
                x, y, w, h = cv2.boundingRect(largest_contour)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø—ã
                padding = 0.1
                x = max(0, int(x - w * padding))
                y = max(0, int(y - h * padding))
                w = min(cv_image.shape[1] - x, int(w * (1 + 2 * padding)))
                h = min(cv_image.shape[0] - y, int(h * (1 + 2 * padding)))
                
                # –û–±—Ä–µ–∑–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                cropped = cv_image[y:y+h, x:x+w]
                return Image.fromarray(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–µ–∑–∫–∏: {e}")
        
        return image
    
    def analyze_image(self, image, use_ensemble=True):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            processed_image = self.preprocess_image(image)
            
            if isinstance(processed_image, torch.Tensor):
                processed_image = processed_image.unsqueeze(0)
            else:
                processed_image = self.transform(processed_image).unsqueeze(0)
            
            processed_image = processed_image.to(self.device)
            
            if self.trained:
                if use_ensemble:
                    return self._ensemble_prediction(processed_image)
                else:
                    return self._single_prediction(processed_image)
            else:
                return self._generate_demo_result()
                
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
    
    def _single_prediction(self, image_tensor):
        """–û–¥–∏–Ω–æ—á–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        with torch.no_grad():
            cleanliness_logits, damage_logits, overall_logits = self.model(image_tensor)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            cleanliness_probs = torch.softmax(cleanliness_logits, dim=1)
            damage_probs = torch.softmax(damage_logits, dim=1)
            overall_probs = torch.softmax(overall_logits, dim=1)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            cleanliness_pred = torch.argmax(cleanliness_probs, dim=1).item()
            damage_pred = torch.argmax(damage_probs, dim=1).item()
            overall_pred = torch.argmax(overall_probs, dim=1).item()
            
            # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            cleanliness_conf = float(cleanliness_probs[0][cleanliness_pred])
            damage_conf = float(damage_probs[0][damage_pred])
            overall_conf = float(overall_probs[0][overall_pred])
            
            # –ö–ª–∞—Å—Å—ã
            cleanliness_class = self.class_names['cleanliness'][cleanliness_pred]
            damage_class = self.class_names['damage'][damage_pred]
            overall_class = self.class_names['overall'][overall_pred]
            
            return self._format_improved_result(
                cleanliness_class, damage_class, overall_class,
                cleanliness_conf, damage_conf, overall_conf, trained=True
            )
    
    def _ensemble_prediction(self, image_tensor):
        """–ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏"""
        predictions = []
        
        # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        predictions.append(self._single_prediction(image_tensor))
        
        # –ê—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏
        for _ in range(3):
            try:
                # –°–æ–∑–¥–∞–µ–º –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
                aug_image = self.augment_transform(self.preprocess_image(image_tensor.squeeze(0).cpu()))
                aug_image = aug_image.unsqueeze(0).to(self.device)
                predictions.append(self._single_prediction(aug_image))
            except:
                continue
        
        # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        return self._average_predictions(predictions)
    
    def _average_predictions(self, predictions):
        """–£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        if not predictions:
            return self._generate_demo_result()
        
        # –£—Å—Ä–µ–¥–Ω—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        avg_clean_conf = np.mean([p['cleanliness']['confidence'] for p in predictions])
        avg_damage_conf = np.mean([p['damage']['confidence'] for p in predictions])
        
        # –ë–µ—Ä–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π –∫–ª–∞—Å—Å
        clean_classes = [p['cleanliness']['class'] for p in predictions]
        damage_classes = [p['damage']['class'] for p in predictions]
        
        cleanliness_class = max(set(clean_classes), key=clean_classes.count)
        damage_class = max(set(damage_classes), key=damage_classes.count)
        
        return self._format_improved_result(
            cleanliness_class, damage_class, f"{cleanliness_class} {damage_class.lower()}",
            avg_clean_conf, avg_damage_conf, (avg_clean_conf + avg_damage_conf) / 2, trained=True
        )
    
    def _format_improved_result(self, cleanliness_class, damage_class, overall_class, 
                               clean_conf, damage_conf, overall_conf, trained=False):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if clean_conf > self.confidence_threshold and damage_conf > self.confidence_threshold:
            if cleanliness_class == '–ß–∏—Å—Ç—ã–π' and damage_class == '–¶–µ–ª—ã–π':
                overall = '–û—Ç–ª–∏—á–Ω–æ–µ'
                quality_score = 95
            elif cleanliness_class == '–ì—Ä—è–∑–Ω—ã–π' and damage_class == '–¶–µ–ª—ã–π':
                overall = '–•–æ—Ä–æ—à–µ–µ (—Ç—Ä–µ–±—É–µ—Ç –º–æ–π–∫–∏)'
                quality_score = 75
            elif cleanliness_class == '–ß–∏—Å—Ç—ã–π' and damage_class == '–ë–∏—Ç—ã–π':
                overall = '–¢—Ä–µ–±—É–µ—Ç —Ä–µ–º–æ–Ω—Ç–∞'
                quality_score = 60
            else:
                overall = '–ü–ª–æ—Ö–æ–µ (—Ç—Ä–µ–±—É–µ—Ç —Ä–µ–º–æ–Ω—Ç–∞ –∏ –º–æ–π–∫–∏)'
                quality_score = 40
        else:
            overall = '–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)'
            quality_score = 50
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —á–∏—Å—Ç–æ—Ç–µ
        if cleanliness_class == '–ì—Ä—è–∑–Ω—ã–π':
            if clean_conf > 0.8:
                recommendations.append('üöø –ê–≤—Ç–æ–º–æ–±–∏–ª—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ –º–æ–π–∫–µ')
                recommendations.append('üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–ª–Ω–∞—è –º–æ–π–∫–∞ –∫—É–∑–æ–≤–∞ –∏ —Å–∞–ª–æ–Ω–∞')
            else:
                recommendations.append('üßΩ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–º—ã—Ç—å –∞–≤—Ç–æ–º–æ–±–∏–ª—å')
            recommendations.append('‚≠ê –ß–∏—Å—Ç—ã–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å –ø–æ–≤—ã—à–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ –≤–æ–¥–∏—Ç–µ–ª—è')
            recommendations.append('üì∏ –°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ –ø–æ—Å–ª–µ –º–æ–π–∫–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è')
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º
        if damage_class == '–ë–∏—Ç—ã–π':
            if damage_conf > 0.8:
                recommendations.append('‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è')
                recommendations.append('üîß –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π —Ç–µ—Ö–æ—Å–º–æ—Ç—Ä –∏ —Ä–µ–º–æ–Ω—Ç')
                recommendations.append('üìû –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫—É inDrive')
            else:
                recommendations.append('üîç –í–æ–∑–º–æ–∂–Ω—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Å–º–æ—Ç—Ä')
                recommendations.append('üì∑ –°–¥–µ–ª–∞–π—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏')
            recommendations.append('üö´ –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∑–∞–∫–∞–∑—ã –¥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è')
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if not recommendations:
            recommendations.append('‚úÖ –ê–≤—Ç–æ–º–æ–±–∏–ª—å –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏!')
            recommendations.append('üåü –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ —Ç–∞–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –≤—ã—Å–æ–∫–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞')
            recommendations.append('ÔøΩÔøΩ –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–∞–±–æ—Ç—É')
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        if quality_score < 70:
            recommendations.append('üìä –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–ª—É—á—à–∏—Ç—å –æ–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—è')
        
        return {
            'cleanliness': {
                'class': cleanliness_class,
                'confidence': clean_conf,
                'status': 'high' if clean_conf > 0.8 else 'medium' if clean_conf > 0.6 else 'low'
            },
            'damage': {
                'class': damage_class,
                'confidence': damage_conf,
                'status': 'high' if damage_conf > 0.8 else 'medium' if damage_conf > 0.6 else 'low'
            },
            'overall_condition': overall,
            'quality_score': quality_score,
            'overall_class': overall_class,
            'overall_confidence': overall_conf,
            'recommendations': recommendations,
            'model_trained': trained,
            'analysis_quality': 'high' if min(clean_conf, damage_conf) > 0.7 else 'medium'
        }
    
    def _generate_demo_result(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –¥–µ–º–æ-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        scenarios = [
            {'clean': 0, 'damage': 0, 'clean_conf': 0.94, 'damage_conf': 0.91},
            {'clean': 1, 'damage': 0, 'clean_conf': 0.89, 'damage_conf': 0.95},
            {'clean': 0, 'damage': 1, 'clean_conf': 0.78, 'damage_conf': 0.85},
            {'clean': 1, 'damage': 1, 'clean_conf': 0.92, 'damage_conf': 0.81},
        ]
        
        scenario = random.choice(scenarios)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å
        clean_conf = max(0.6, min(0.99, scenario['clean_conf'] + random.uniform(-0.08, 0.08)))
        damage_conf = max(0.6, min(0.99, scenario['damage_conf'] + random.uniform(-0.08, 0.08)))
        
        cleanliness_class = self.class_names['cleanliness'][scenario['clean']]
        damage_class = self.class_names['damage'][scenario['damage']]
        overall_class = f"{cleanliness_class} {damage_class.lower()}"
        
        return self._format_improved_result(
            cleanliness_class, damage_class, overall_class,
            clean_conf, damage_conf, (clean_conf + damage_conf) / 2, trained=False
        )

# –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
CarConditionClassifier = ImprovedCarConditionClassifier
CarAnalyzer = AdvancedCarAnalyzer
