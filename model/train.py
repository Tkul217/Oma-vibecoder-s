#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ 3 —Ç–∏–ø–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import pandas as pd
from PIL import Image
from pathlib import Path
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
import json
import os
from car_model import CarConditionClassifier

class SimpleCarDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.root_dir = Path(root_dir)
        self.transform = transform
        
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(self.data)}")
        print(f"   –ß–∏—Å—Ç—ã–µ: {len(self.data[self.data['cleanliness'] == 'clean'])}")
        print(f"   –ì—Ä—è–∑–Ω—ã–µ: {len(self.data[self.data['cleanliness'] == 'dirty'])}")
        print(f"   –¶–µ–ª—ã–µ: {len(self.data[self.data['damage'] == 'intact'])}")
        print(f"   –ë–∏—Ç—ã–µ: {len(self.data[self.data['damage'] == 'damaged'])}")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        row = self.data.iloc[idx]
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img_path = self.root_dir / row['image_path']
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {img_path}: {e}")
            # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
            image = Image.new('RGB', (224, 224), color=(128, 128, 128))
        
        if self.transform:
            image = self.transform(image)
        
        # –ú–µ—Ç–∫–∏ (0/1)
        cleanliness_label = 0 if row['cleanliness'] == 'clean' else 1
        damage_label = 0 if row['damage'] == 'intact' else 1
        
        return {
            'image': image,
            'cleanliness': torch.tensor(cleanliness_label, dtype=torch.long),
            'damage': torch.tensor(damage_label, dtype=torch.long)
        }

def train_simple_model(epochs=15, batch_size=8, lr=0.001):
    """–ü—Ä–æ—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    
    print("üöó –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π")
    print("=" * 45)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
    if not os.path.exists('data/dataset.csv'):
        print("‚ùå –§–∞–π–ª data/dataset.csv –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("üí° –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python prepare_3folders.py")
        return False
    
    # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop(224),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    df = pd.read_csv('data/dataset.csv')
    train_df = df[df['split'] == 'train'].copy()
    val_df = df[df['split'] == 'val'].copy()
    
    print(f"   –û–±—É—á–∞—é—â–∏—Ö: {len(train_df)}")
    print(f"   –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö: {len(val_df)}")
    
    if len(train_df) < 4:
        print("‚ö†Ô∏è –û—á–µ–Ω—å –º–∞–ª–æ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö! –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 20-50 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ CSV —Ñ–∞–π–ª—ã
    train_df.to_csv('train_temp.csv', index=False)
    val_df.to_csv('val_temp.csv', index=False)
    
    # –î–∞—Ç–∞—Å–µ—Ç—ã
    train_dataset = SimpleCarDataset('train_temp.csv', 'data', train_transform)
    val_dataset = SimpleCarDataset('val_temp.csv', 'data', val_transform) 
    
    # DataLoaders
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    # –ú–æ–¥–µ–ª—å
    print("\nü§ñ –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    model = CarConditionClassifier()
    model.to(device)
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    
    # –ò—Å—Ç–æ—Ä–∏—è
    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}
    best_val_acc = 0.0
    
    print(f"\nüéØ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {epochs} —ç–ø–æ—Ö...")
    print("=" * 45)
    
    for epoch in range(epochs):
        # –û–ë–£–ß–ï–ù–ò–ï
        model.train()
        train_loss = 0.0
        train_batches = 0
        
        print(f"\n–≠–ø–æ—Ö–∞ {epoch+1}/{epochs}")
        pbar = tqdm(train_loader, desc="–û–±—É—á–µ–Ω–∏–µ")
        
        for batch in pbar:
            images = batch['image'].to(device)
            clean_labels = batch['cleanliness'].to(device)
            damage_labels = batch['damage'].to(device)
            
            optimizer.zero_grad()
            
            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            clean_logits, damage_logits = model(images)
            
            # Loss (–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
            clean_loss = criterion(clean_logits, clean_labels)
            damage_loss = criterion(damage_logits, damage_labels)
            total_loss = clean_loss + damage_loss
            
            # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥
            total_loss.backward()
            optimizer.step()
            
            train_loss += total_loss.item()
            train_batches += 1
            
            pbar.set_postfix({'loss': total_loss.item()})
        
        # –í–ê–õ–ò–î–ê–¶–ò–Ø
        model.eval()
        val_loss = 0.0
        correct_clean = 0
        correct_damage = 0
        total = 0
        
        with torch.no_grad():
            pbar = tqdm(val_loader, desc="–í–∞–ª–∏–¥–∞—Ü–∏—è")
            for batch in pbar:
                images = batch['image'].to(device)
                clean_labels = batch['cleanliness'].to(device)
                damage_labels = batch['damage'].to(device)
                
                clean_logits, damage_logits = model(images)
                
                # Loss
                clean_loss = criterion(clean_logits, clean_labels)
                damage_loss = criterion(damage_logits, damage_labels)
                total_loss = clean_loss + damage_loss
                val_loss += total_loss.item()
                
                # –¢–æ—á–Ω–æ—Å—Ç—å
                _, clean_pred = torch.max(clean_logits, 1)
                _, damage_pred = torch.max(damage_logits, 1)
                
                correct_clean += (clean_pred == clean_labels).sum().item()
                correct_damage += (damage_pred == damage_labels).sum().item()
                total += images.size(0)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        avg_train_loss = train_loss / train_batches
        avg_val_loss = val_loss / len(val_loader)
        clean_acc = correct_clean / total
        damage_acc = correct_damage / total
        combined_acc = (clean_acc + damage_acc) / 2
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
        history['train_loss'].append(avg_train_loss)
        history['val_loss'].append(avg_val_loss)
        history['val_acc'].append(combined_acc)
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}")
        print(f"Clean Acc: {clean_acc:.4f} | Damage Acc: {damage_acc:.4f} | Combined: {combined_acc:.4f}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if combined_acc > best_val_acc:
            best_val_acc = combined_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': combined_acc,
                'clean_acc': clean_acc,
                'damage_acc': damage_acc
            }, 'best_model.pth')
            print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å! –¢–æ—á–Ω–æ—Å—Ç—å: {combined_acc:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    torch.save({
        'model_state_dict': model.state_dict(),
        'history': history,
        'final_accuracy': best_val_acc
    }, 'final_model.pth')
    
    # –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Val Loss')
    plt.title('Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(history['val_acc'], label='Validation Accuracy')
    plt.title('Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig('training_results.png', dpi=150)
    plt.show()
    
    # –û—á–∏—Å—Ç–∫–∞
    os.remove('train_temp.csv')
    os.remove('val_temp.csv')
    
    print(f"\nüéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"‚úÖ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {best_val_acc:.4f}")
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: best_model.pth")
    print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫: training_results.png")
    
    return True

if __name__ == "__main__":
    # –ü—Ä–æ—Å—Ç—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    config = {
        'epochs': 15,        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö  
        'batch_size': 8,     # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (—É–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
        'lr': 0.001         # Learning rate
    }
    
    print("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è:")
    for key, value in config.items():
        print(f"   {key}: {value}")
    
    success = train_simple_model(**config)
    
    if success:
        print(f"\nüöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print(f"1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≥—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è: training_results.png")
        print(f"2. –û–±–Ω–æ–≤–∏—Ç–µ app.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
        print(f"3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ API: python app.py")
    else:
        print(f"\n‚ùå –û–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.")