# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Python ML –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º

## üéØ –í–∞—Ä–∏–∞–Ω—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### –í–∞—Ä–∏–∞–Ω—Ç 1: Python –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å (–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π)

–°–æ–∑–¥–∞–π—Ç–µ –æ—Ç–¥–µ–ª—å–Ω—ã–π Python API —Å–µ—Ä–≤–µ—Ä:

```python
# ml_service/app.py
from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
from PIL import Image
import io
import base64

app = Flask(__name__)
CORS(app)

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏
class CarAnalyzer:
    def __init__(self):
        # –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à–∏ –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        self.cleanliness_model = torch.load('models/cleanliness_model.pth')
        self.condition_model = torch.load('models/condition_model.pth')
        self.cleanliness_model.eval()
        self.condition_model.eval()
    
    def analyze(self, image):
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
        # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        pass

analyzer = CarAnalyzer()

@app.route('/analyze', methods=['POST'])
def analyze_car():
    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        file = request.files['image']
        image = Image.open(file.stream)
        
        # –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é ML –º–æ–¥–µ–ª–∏
        result = analyzer.analyze(image)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'OK'})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

```bash
# ml_service/requirements.txt
flask==2.3.3
flask-cors==4.0.0
torch>=1.9.0
torchvision>=0.10.0
Pillow>=8.3.0
numpy>=1.21.0
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ Python —Å–∫—Ä–∏–ø—Ç–∞

–û–±–Ω–æ–≤–∏—Ç–µ Node.js —Å–µ—Ä–≤–µ—Ä –¥–ª—è –≤—ã–∑–æ–≤–∞ Python:

```javascript
// server/server.js - –¥–æ–±–∞–≤–∏—Ç—å –≤ —Ñ—É–Ω–∫—Ü–∏—é analyzeCarImage
const { spawn } = require('child_process');
const path = require('path');

function analyzeCarImage(imagePath) {
  return new Promise((resolve, reject) => {
    const pythonScript = path.join(__dirname, '../ml/analyze.py');
    const python = spawn('python', [pythonScript, imagePath]);
    
    let result = '';
    let error = '';
    
    python.stdout.on('data', (data) => {
      result += data.toString();
    });
    
    python.stderr.on('data', (data) => {
      error += data.toString();
    });
    
    python.on('close', (code) => {
      if (code === 0) {
        try {
          const analysisResult = JSON.parse(result);
          resolve(analysisResult);
        } catch (e) {
          reject(new Error('Invalid JSON response from ML model'));
        }
      } else {
        reject(new Error(`ML analysis failed: ${error}`));
      }
    });
  });
}
```

## üöÄ –ü–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ ML –º–æ–¥–µ–ª–∏

–í–∞—à –¥—Ä—É–≥ –¥–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞—Ç—å —Å–∫—Ä–∏–ø—Ç `ml/analyze.py`:

```python
#!/usr/bin/env python3
import sys
import json
import torch
from PIL import Image
import torchvision.transforms as transforms

def load_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    cleanliness_model = torch.load('models/cleanliness_model.pth', map_location='cpu')
    condition_model = torch.load('models/condition_model.pth', map_location='cpu')
    
    cleanliness_model.eval()
    condition_model.eval()
    
    return cleanliness_model, condition_model

def preprocess_image(image_path):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    image = Image.open(image_path).convert('RGB')
    return transform(image).unsqueeze(0)

def analyze_image(image_path):
    """–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
        cleanliness_model, condition_model = load_models()
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        image_tensor = preprocess_image(image_path)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        with torch.no_grad():
            # –ê–Ω–∞–ª–∏–∑ —á–∏—Å—Ç–æ—Ç—ã
            clean_outputs = cleanliness_model(image_tensor)
            clean_probs = torch.nn.functional.softmax(clean_outputs, dim=1)
            clean_confidence = float(clean_probs.max())
            cleanliness = 'clean' if clean_outputs.argmax() == 0 else 'dirty'
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
            condition_outputs = condition_model(image_tensor)
            condition_probs = torch.nn.functional.softmax(condition_outputs, dim=1)
            condition_confidence = float(condition_probs.max())
            condition = 'intact' if condition_outputs.argmax() == 0 else 'damaged'
        
        return {
            'cleanliness': cleanliness,
            'cleanlinessConfidence': clean_confidence,
            'condition': condition,
            'conditionConfidence': condition_confidence,
            'processingTime': 1200  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è
        }
        
    except Exception as e:
        return {'error': str(e)}

if __name__ == '__main__':
    if len(sys.argv) != 2:
        print(json.dumps({'error': 'Usage: python analyze.py <image_path>'}))
        sys.exit(1)
    
    image_path = sys.argv[1]
    result = analyze_image(image_path)
    print(json.dumps(result))
```

### –®–∞–≥ 2: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
project/
‚îú‚îÄ‚îÄ src/                    # React frontend
‚îú‚îÄ‚îÄ server/                 # Node.js API
‚îú‚îÄ‚îÄ ml/                     # Python ML –∫–æ–¥
‚îÇ   ‚îú‚îÄ‚îÄ analyze.py         # –°–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∞
‚îÇ   ‚îú‚îÄ‚îÄ models/            # –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleanliness_model.pth
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ condition_model.pth
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ ml_service/            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π Python API
    ‚îú‚îÄ‚îÄ app.py
    ‚îî‚îÄ‚îÄ requirements.txt
```

### –®–∞–≥ 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
cd ml
pip install -r requirements.txt

# –ò–ª–∏ –¥–ª—è –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
cd ml_service
pip install -r requirements.txt
```

### –®–∞–≥ 4: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Node.js —Å–µ—Ä–≤–µ—Ä–∞

–ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å, –æ–±–Ω–æ–≤–∏—Ç–µ URL –≤ server.js:

```javascript
// –í–º–µ—Å—Ç–æ mock —Ñ—É–Ω–∫—Ü–∏–∏
async function analyzeCarImage(imagePath) {
  try {
    const formData = new FormData();
    const fileStream = fs.createReadStream(imagePath);
    formData.append('image', fileStream);
    
    const response = await fetch('http://localhost:5000/analyze', {
      method: 'POST',
      body: formData
    });
    
    return await response.json();
  } catch (error) {
    throw new Error(`ML service error: ${error.message}`);
  }
}
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

### Docker Compose –¥–ª—è –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤

```yaml
# docker-compose.yml
version: '3.8'
services:
  frontend:
    build: .
    ports:
      - "3000:3000"
    depends_on:
      - api
      - ml-service

  api:
    build: ./server
    ports:
      - "3001:3001"
    depends_on:
      - ml-service

  ml-service:
    build: ./ml_service
    ports:
      - "5000:5000"
    volumes:
      - ./ml/models:/app/models
```

### Dockerfile –¥–ª—è ML —Å–µ—Ä–≤–∏—Å–∞

```dockerfile
# ml_service/Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 5000

CMD ["python", "app.py"]
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

```bash
# –¢–µ—Å—Ç Python —Å–∫—Ä–∏–ø—Ç–∞
python ml/analyze.py path/to/test/image.jpg

# –¢–µ—Å—Ç –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
curl -X POST -F "image=@test_image.jpg" http://localhost:5000/analyze

# –¢–µ—Å—Ç –ø–æ–ª–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
# –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
```

## üìã –ß–µ–∫–ª–∏—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

- [ ] ML –º–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ PyTorch
- [ ] –°–æ–∑–¥–∞–Ω —Å–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∞ `analyze.py`
- [ ] –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- [ ] –û–±–Ω–æ–≤–ª–µ–Ω Node.js —Å–µ—Ä–≤–µ—Ä –¥–ª—è –≤—ã–∑–æ–≤–∞ Python
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ —Ä–∞–±–æ—Ç–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
- [ ] –ù–∞—Å—Ç—Ä–æ–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
- [ ] –î–æ–±–∞–≤–ª–µ–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

## üö® –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

1. **–ü—É—Ç—å –∫ Python**: –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ `python` –¥–æ—Å—Ç—É–ø–µ–Ω –≤ PATH
2. **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**: –í—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏
3. **–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–µ–π**: –ë–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –¥–æ–ª–≥–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è
4. **–ü–∞–º—è—Ç—å**: PyTorch –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É—é—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ RAM
5. **CORS**: –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ Python
- –ö–µ—à–∏—Ä—É–π—Ç–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç–∏
- –î–æ–±–∞–≤—å—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –†–µ–∞–ª–∏–∑—É–π—Ç–µ graceful shutdown –¥–ª—è —Å–µ—Ä–≤–∏—Å–æ–≤
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ (`torch.cuda.is_available()`)