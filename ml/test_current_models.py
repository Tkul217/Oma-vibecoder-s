#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
"""

import sys
import os
from pathlib import Path
import json

def test_model_loading():
    """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π"""
    
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –¢–ï–ö–£–©–ò–• –ú–û–î–ï–õ–ï–ô")
    print("=" * 50)
    
    models_dir = Path('models')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–µ–π
    cleanliness_model = models_dir / 'cleanliness_model.pth'
    condition_model = models_dir / 'condition_model.pth'
    
    print(f"üìÅ –ü–∞–ø–∫–∞ –º–æ–¥–µ–ª–µ–π: {models_dir.absolute()}")
    print(f"üßΩ –ú–æ–¥–µ–ª—å —á–∏—Å—Ç–æ—Ç—ã: {'‚úÖ' if cleanliness_model.exists() else '‚ùå'}")
    print(f"üîß –ú–æ–¥–µ–ª—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {'‚úÖ' if condition_model.exists() else '‚ùå'}")
    
    if cleanliness_model.exists():
        size = cleanliness_model.stat().st_size / (1024*1024)
        print(f"   –†–∞–∑–º–µ—Ä: {size:.1f} MB")
    
    if condition_model.exists():
        size = condition_model.stat().st_size / (1024*1024)
        print(f"   –†–∞–∑–º–µ—Ä: {size:.1f} MB")

def test_analyze_script():
    """–¢–µ—Å—Ç —Å–∫—Ä–∏–ø—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
    
    print("\nüîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–ö–†–ò–ü–¢–ê –ê–ù–ê–õ–ò–ó–ê")
    print("=" * 50)
    
    # –ò—â–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    test_images = []
    data_dir = Path('../data')
    
    for folder in ['clean', 'dirty', 'intact', 'damaged']:
        folder_path = data_dir / folder
        if folder_path.exists():
            for ext in ['.jpg', '.jpeg', '.png']:
                images = list(folder_path.glob(f'*{ext}'))
                if images:
                    test_images.extend(images[:1])
    
    if not test_images:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")
        print("üí° –î–æ–±–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–∏ data/clean, data/dirty, etc.")
        return
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø–µ—Ä–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    test_image = test_images[0]
    print(f"üñºÔ∏è –¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {test_image}")
    
    try:
        import subprocess
        result = subprocess.run([
            sys.executable, 'analyze.py', str(test_image)
        ], capture_output=True, text=True, cwd='.')
        
        if result.returncode == 0:
            print("‚úÖ –°–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
            print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
            try:
                data = json.loads(result.stdout)
                print(f"   –ß–∏—Å—Ç–æ—Ç–∞: {data.get('cleanliness', 'N/A')} ({data.get('cleanlinessConfidence', 0):.2f})")
                print(f"   –°–æ—Å—Ç–æ—è–Ω–∏–µ: {data.get('condition', 'N/A')} ({data.get('conditionConfidence', 0):.2f})")
                print(f"   –í—Ä–µ–º—è: {data.get('processingTime', 0)}ms")
            except:
                print(result.stdout)
        else:
            print("‚ùå –û—à–∏–±–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:")
            print(result.stderr)
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")

def check_data_distribution():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    
    print("\nüìä –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•")
    print("=" * 50)
    
    data_dir = Path('../data')
    
    if not data_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ data/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    folders = ['clean', 'dirty', 'intact', 'damaged']
    total_images = 0
    
    for folder in folders:
        folder_path = data_dir / folder
        if folder_path.exists():
            image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
            images = [f for f in folder_path.iterdir() 
                     if f.is_file() and f.suffix.lower() in image_extensions]
            
            count = len(images)
            total_images += count
            
            status = "‚úÖ" if count >= 100 else "‚ö†Ô∏è" if count > 0 else "‚ùå"
            print(f"  {status} {folder}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        else:
            print(f"  ‚ùå {folder}: –ø–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    print(f"\nüìà –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
    
    if total_images < 400:
        print("‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è!")
        print("üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 100 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –∫–ª–∞—Å—Å")

def main():
    print("üöó –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´ –ê–ù–ê–õ–ò–ó–ê –ê–í–¢–û–ú–û–ë–ò–õ–ï–ô")
    print("=" * 60)
    
    test_model_loading()
    check_data_distribution() 
    test_analyze_script()
    
    print("\n" + "=" * 60)
    print("üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("1. –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ - –ø–µ—Ä–µ–æ–±—É—á–∏—Ç–µ")
    print("2. –ï—Å–ª–∏ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö - –∑–∞–≥—Ä—É–∑–∏—Ç–µ –±–æ–ª—å—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print("3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: python download_datasets.py")
    print("4. –ó–∞—Ç–µ–º: python train_separate_models.py")

if __name__ == "__main__":
    main()