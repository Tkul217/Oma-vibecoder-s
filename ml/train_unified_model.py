#!/usr/bin/env python3
"""
–û–±—É—á–µ–Ω–∏–µ –µ–¥–∏–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
–ú–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç 4 –∫–ª–∞—Å—Å–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ:
- clean_intact (—á–∏—Å—Ç—ã–π —Ü–µ–ª—ã–π)
- clean_damaged (—á–∏—Å—Ç—ã–π –±–∏—Ç—ã–π)  
- dirty_intact (–≥—Ä—è–∑–Ω—ã–π —Ü–µ–ª—ã–π)
- dirty_damaged (–≥—Ä—è–∑–Ω—ã–π –±–∏—Ç—ã–π)

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:
data/
‚îú‚îÄ‚îÄ clean_intact/     # –ß–∏—Å—Ç—ã–µ —Ü–µ–ª—ã–µ –º–∞—à–∏–Ω—ã
‚îú‚îÄ‚îÄ clean_damaged/    # –ß–∏—Å—Ç—ã–µ –±–∏—Ç—ã–µ –º–∞—à–∏–Ω—ã
‚îú‚îÄ‚îÄ dirty_intact/     # –ì—Ä—è–∑–Ω—ã–µ —Ü–µ–ª—ã–µ –º–∞—à–∏–Ω—ã
‚îî‚îÄ‚îÄ dirty_damaged/    # –ì—Ä—è–∑–Ω—ã–µ –±–∏—Ç—ã–µ –º–∞—à–∏–Ω—ã
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
from torchvision import models
from PIL import Image
import os
import json
from tqdm import tqdm
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import shutil

class CarDataset(Dataset):
    """–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π"""
    
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        label = self.labels[idx]
        
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            image = Image.new('RGB', (224, 224), color='black')
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

class UnifiedCarModel(nn.Module):
    """–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π (4 –∫–ª–∞—Å—Å–∞)"""
    
    def __init__(self, num_classes=4, pretrained=True):
        super(UnifiedCarModel, self).__init__()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ResNet50 –∫–∞–∫ backbone
        self.backbone = models.resnet50(pretrained=pretrained)
        
        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —Ä–∞–Ω–Ω–∏–µ —Å–ª–æ–∏ –¥–ª—è transfer learning
        for param in list(self.backbone.parameters())[:-30]:
            param.requires_grad = False
        
        # –ó–∞–º–µ–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 1024),
            nn.ReLU(),
            nn.BatchNorm1d(1024),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.2),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        return self.backbone(x)

def load_data_from_folders(data_dir):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ 4 –ø–∞–ø–æ–∫"""
    
    # –ú–∞–ø–ø–∏–Ω–≥ –ø–∞–ø–æ–∫ –Ω–∞ –∫–ª–∞—Å—Å—ã
    class_mapping = {
        'clean_intact': 0,     # —á–∏—Å—Ç—ã–π —Ü–µ–ª—ã–π
        'clean_damaged': 1,    # —á–∏—Å—Ç—ã–π –±–∏—Ç—ã–π
        'dirty_intact': 2,     # –≥—Ä—è–∑–Ω—ã–π —Ü–µ–ª—ã–π
        'dirty_damaged': 3     # –≥—Ä—è–∑–Ω—ã–π –±–∏—Ç—ã–π
    }
    
    image_paths = []
    labels = []
    class_counts = defaultdict(int)
    
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–∞–ø–æ–∫...")
    
    for folder_name, class_id in class_mapping.items():
        folder_path = os.path.join('../data', folder_name)

        if not os.path.exists(folder_path):
            print(f"‚ö†Ô∏è  –ü–∞–ø–∫–∞ {folder_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            continue

        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}

        for filename in os.listdir(folder_path):
            if any(filename.lower().endswith(ext) for ext in valid_extensions):
                image_path = os.path.join(folder_path, filename)
                image_paths.append(image_path)
                labels.append(class_id)
                class_counts[folder_name] += 1

    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö:")
    for folder_name, count in class_counts.items():
        print(f"  {folder_name}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"  –í—Å–µ–≥–æ: {len(image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

    return image_paths, labels, class_mapping

def get_transforms():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""

    # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop(224),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(degrees=15),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])

    return train_transform, val_transform

def train_model(model, train_loader, val_loader, num_epochs=50, device='cuda', save_path='models/'):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    os.makedirs(save_path, exist_ok=True)

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.5)

    best_acc = 0.0
    train_losses = []
    val_accuracies = []

    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {device}")
    print(f"–≠–ø–æ—Ö: {num_epochs}")
    print("-" * 60)

    for epoch in range(num_epochs):
        print(f'\n–≠–ø–æ—Ö–∞ {epoch+1}/{num_epochs}')

        # –§–∞–∑–∞ –æ–±—É—á–µ–Ω–∏—è
        model.train()
        running_loss = 0.0
        running_corrects = 0
        total_samples = 0

        train_bar = tqdm(train_loader, desc="–û–±—É—á–µ–Ω–∏–µ")
        for inputs, labels in train_bar:
            inputs = inputs.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

            _, preds = torch.max(outputs, 1)
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)
            total_samples += inputs.size(0)

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            current_acc = running_corrects.double() / total_samples
            train_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'acc': f'{current_acc:.4f}'
            })

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)
        train_losses.append(epoch_loss)

        print(f'–û–±—É—á–µ–Ω–∏–µ - Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

        # –§–∞–∑–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        model.eval()
        val_corrects = 0
        val_total = 0
        all_preds = []
        all_labels = []

        with torch.no_grad():
            val_bar = tqdm(val_loader, desc="–í–∞–ª–∏–¥–∞—Ü–∏—è")
            for inputs, labels in val_bar:
                inputs = inputs.to(device)
                labels = labels.to(device)

                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)

                val_corrects += torch.sum(preds == labels.data)
                val_total += labels.size(0)

                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        val_acc = val_corrects.double() / val_total
        val_accuracies.append(val_acc)

        print(f'–í–∞–ª–∏–¥–∞—Ü–∏—è - Acc: {val_acc:.4f}')

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), os.path.join(save_path, 'best_unified_model.pth'))
            print(f'‚úÖ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞! –¢–æ—á–Ω–æ—Å—Ç—å: {best_acc:.4f}')

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ learning rate
        scheduler.step(val_acc)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫–∞–∂–¥—ã–µ 10 —ç–ø–æ—Ö
        if (epoch + 1) % 10 == 0:
            torch.save(model.state_dict(), os.path.join(save_path, f'model_epoch_{epoch+1}.pth'))

    print(f"\nüéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {best_acc:.4f}")

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    plot_training_history(train_losses, val_accuracies, save_path)

    # –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    class_names = ['clean_intact', 'clean_damaged', 'dirty_intact', 'dirty_damaged']
    print("\nüìä –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print(classification_report(all_labels, all_preds, target_names=class_names))

    # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
    plot_confusion_matrix(all_labels, all_preds, class_names, save_path)

    return model

def plot_training_history(train_losses, val_accuracies, save_path):
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""

    plt.figure(figsize=(15, 5))

    # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, 'b-', label='Training Loss')
    plt.title('Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
    plt.subplot(1, 2, 2)
    plt.plot([acc.cpu().numpy() for acc in val_accuracies], 'r-', label='Validation Accuracy')
    plt.title('Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join(save_path, 'training_history.png'), dpi=300, bbox_inches='tight')
    plt.close()

    print("üìà –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ training_history.png")

def plot_confusion_matrix(y_true, y_pred, class_names, save_path):
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫"""

    cm = confusion_matrix(y_true, y_pred)

    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')
    plt.close()

    print("üìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ confusion_matrix.png")

def create_inference_script(class_mapping, save_path):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞"""

    inference_code = f'''#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
"""

import torch
import torchvision.transforms as transforms
from PIL import Image
import json
import sys
import os

# –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤
CLASS_MAPPING = {class_mapping}
REVERSE_MAPPING = {{v: k for k, v in CLASS_MAPPING.items()}}

class UnifiedCarModel(torch.nn.Module):
    def __init__(self, num_classes=4):
        super(UnifiedCarModel, self).__init__()
        from torchvision import models

        self.backbone = models.resnet50(pretrained=False)
        num_features = self.backbone.fc.in_features
        self.backbone.fc = torch.nn.Sequential(
            torch.nn.Dropout(0.5),
            torch.nn.Linear(num_features, 1024),
            torch.nn.ReLU(),
            torch.nn.BatchNorm1d(1024),
            torch.nn.Dropout(0.3),
            torch.nn.Linear(1024, 512),
            torch.nn.ReLU(),
            torch.nn.BatchNorm1d(512),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(512, num_classes)
        )

    def forward(self, x):
        return self.backbone(x)

def load_model(model_path):
    model = UnifiedCarModel(num_classes=4)
    model.load_state_dict(torch.load(model_path, map_location='cpu'))
    model.eval()
    return model

def preprocess_image(image_path):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])

    image = Image.open(image_path).convert('RGB')
    return transform(image).unsqueeze(0)

def predict(model, image_tensor):
    with torch.no_grad():
        outputs = model(image_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        confidence, predicted = torch.max(probabilities, 1)

        class_name = REVERSE_MAPPING[predicted.item()]

        # –†–∞–∑–±–∏—Ä–∞–µ–º –∫–ª–∞—Å—Å –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        parts = class_name.split('_')
        cleanliness = parts[0]  # clean –∏–ª–∏ dirty
        condition = parts[1]    # intact –∏–ª–∏ damaged

        return {{
            'cleanliness': cleanliness,
            'cleanlinessConfidence': confidence.item(),
            'condition': condition,
            'conditionConfidence': confidence.item(),
            'full_class': class_name,
            'class_probabilities': {{
                REVERSE_MAPPING[i]: prob.item()
                for i, prob in enumerate(probabilities[0])
            }}
        }}

def main():
    if len(sys.argv) != 2:
        print(json.dumps({{"error": "Usage: python inference.py <image_path>"}}))
        sys.exit(1)

    image_path = sys.argv[1]
    model_path = "best_unified_model.pth"

    try:
        model = load_model(model_path)
        image_tensor = preprocess_image(image_path)
        result = predict(model, image_tensor)
        print(json.dumps(result, ensure_ascii=False))
    except Exception as e:
        print(json.dumps({{"error": str(e)}}))
        sys.exit(1)

if __name__ == "__main__":
    main()
'''

    with open(os.path.join(save_path, 'inference.py'), 'w', encoding='utf-8') as f:
        f.write(inference_code)

    print("üîÆ –°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å–æ–∑–¥–∞–Ω: inference.py")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    DATA_DIR = '../data'  # –ü–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
    MODELS_DIR = 'models'
    BATCH_SIZE = 32
    NUM_EPOCHS = 50
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ CUDA
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üñ•Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    try:
        image_paths, labels, class_mapping = load_data_from_folders(DATA_DIR)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        print("\nüìÅ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ —Å–ª–µ–¥—É—é—â–∞—è:")
        print("data/")
        print("‚îú‚îÄ‚îÄ clean_intact/")
        print("‚îú‚îÄ‚îÄ clean_damaged/")
        print("‚îú‚îÄ‚îÄ dirty_intact/")
        print("‚îî‚îÄ‚îÄ dirty_damaged/")
        return
    
    if len(image_paths) == 0:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é
    train_paths, val_paths, train_labels, val_labels = train_test_split(
        image_paths, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    print(f"\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  –û–±—É—á–µ–Ω–∏–µ: {len(train_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"  –í–∞–ª–∏–¥–∞—Ü–∏—è: {len(val_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
    train_transform, val_transform = get_transforms()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    train_dataset = CarDataset(train_paths, train_labels, train_transform)
    val_dataset = CarDataset(val_paths, val_labels, val_transform)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑—á–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, 
                             shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, 
                           shuffle=False, num_workers=4, pin_memory=True)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = UnifiedCarModel(num_classes=4, pretrained=True).to(device)
    
    print(f"\nüß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
    print(f"  Backbone: ResNet50")
    print(f"  –ö–ª–∞—Å—Å—ã: {len(class_mapping)}")
    print(f"  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {sum(p.numel() for p in model.parameters()):,}")
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    trained_model = train_model(model, train_loader, val_loader, 
                               num_epochs=NUM_EPOCHS, device=device, 
                               save_path=MODELS_DIR)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    create_inference_script(class_mapping, MODELS_DIR)
    
    print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"üìÅ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {MODELS_DIR}")
    print(f"üîÆ –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: python {MODELS_DIR}/inference.py <–ø—É—Ç—å_–∫_–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é>")

if __name__ == "__main__":
    main()